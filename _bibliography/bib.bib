---
---

References
==========

@article{BosSud2024,
  title = {Runtime {{Analysis}} of {{Quality Diversity Algorithms}}},
  author = {{Bossek, Jakob and Sudholt, Dirk}},
  year = {{2024}},
  journal = {Algorithmica},
  issn = {1432-0541},
  doi = {10.1007/s00453-024-01254-z},
}

@inproceedings{DietrichEtAl2024,
  author = {{Dietrich, Konstantin and Prager, Raphael and Doerr, Carola and Trautmann, Heike}},
  title = {Hybridizing Target- and SHAP-encoded Features for Algorithm Selection in Mixed-variable Black-box Optimization},
  booktitle = {Parallel Problem Solving from Nature --- PPSN XVIII},
  pages = {1-14},
  year = {{2024}},
  publisher = {Springer International Publishing},
  address = {Cham},
  note = {Accepted}
}

@inproceedings{SeilerEtAl2024,
  author = {{Seiler, Moritz and Skvorc, Urban and Cenikj, Gjorgjina and Doerr, Carola and Trautmann, Heike}},
  title = {Learned Features vs. Classical ELA on Affine BBOB Functions},
  booktitle = {Parallel Problem Solving from Nature --- PPSN XVIII},
  pages = {1-14},
  year = {{2024}},
  publisher = {Springer International Publishing},
  address = {Cham},
  note = {Accepted}
}

@article{PraTra2024,
  author = {{Prager, Raphael Patrick and Trautmann, Heike}},
  journal = {IEEE Transactions on Evolutionary Computation},
  title = {Exploratory Landscape Analysis for Mixed-Variable Problems},
  year = {{2024}},
  volume = {},
  number = {},
  pages = {1-1},
  doi = {10.1109/TEVC.2024.3399560},
}

@inproceedings{RooEtAl24,
author = {{Rook, Jeroen and Hoos, Holger H. and Trautmann, Heike}},
title = {{Multi-objective Ranking using Bootstrap Resampling}},
year = {{2024}},
publisher = {Association for Computing Machinery},
booktitle = {Proceedings of the {{Genetic}} and {{Evolutionary Computation Conference Companion}}},
numpages = {4},
location = {Melbourne, Australia},
series = {{{GECCO '24}}},
address = {New York, NY, USA},
pages        = {155--158},
doi          = {10.1145/3638530.3654436},
}

@inproceedings{BosGri2024,
title = {Generalised {{Kruskal Mutation}} for the {{Multi-Objective Minimum Spanning Tree Problem}}},
booktitle = {Proceedings of the {{Genetic}} and {{Evolutionary Computation Conference}}},
author = {{Bossek, Jakob and Grimme, Christian}},
year = {{2024}},
numpages = {9},
location = {Melbourne, Australia},
series = {{{GECCO}} '24},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
pages = {133--141},
doi = {10.1145/3638529.3654165},
}

@inproceedings{SchEtAl2024,
title = {Guiding {{Quality Diversity}} on {{Monotone Submodular Functions}}: {{Customising}} the {{Feature Space}} by {{Adding Boolean Conjunctions}}},
booktitle = {Proceedings of the {{Genetic}} and {{Evolutionary Computation Conference}}},
author = {{Schmidbauer, Marcus and Opris, Andre and Bossek, Jakob and Neumann, Frank and Sudholt, Dirk}},
year = {{2024}},
numpages = {9},
location = {Melbourne, Australia},
series = {{{GECCO}} '24},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
pages = {1614--1622},
doi = {10.1145/3638529.3654160},
}

@inproceedings{Preuss24,
  author = {{Preuß, Oliver and Rook, Jeroen and Trautmann, Heike}},
  title = {{On the Potential of Multi-Objective Automated Algorithm Configuration on Multi-Modal Multi-Objective Optimisation Problems}},
  booktitle = {{Applications of Evolutionary Computation}},
  year = {{2024}},
  publisher = {{Springer Nature Switzerland}},
  address = {{Cham}},
  pages = {{305-321}},
  isbn = {{978-3-031-56852-7}}
}

@article{46299,
  abstract     = {{The herein proposed Python package pflacco provides a set of numerical features to characterize single-objective continuous and constrained optimization problems. Thereby, pflacco addresses two major challenges in the area optimization. Firstly, it provides the means to develop an understanding of a given problem instance, which is crucial for designing, selecting, or configuring optimization algorithms in general. Secondly, these numerical features can be utilized in the research streams of automated algorithm selection and configuration. While the majority of these landscape features is already available in the R package flacco, our Python implementation offers these tools to an even wider audience and thereby promotes research interests and novel avenues in the area of optimization.}},
  author       = {{Prager, Raphael Patrick and Trautmann, Heike}},
  issn         = {{1063-6560}},
  journal      = {{Evolutionary Computation}},
  pages        = {{1–25}},
  title        = {{{Pflacco: Feature-Based Landscape Analysis of Continuous and Constrained Optimization Problems in Python}}},
  doi          = {{10.1162/evco_a_00341}},
  year         = {{2023}},
}

@article{48883,
  abstract     = {{Classic automated algorithm selection (AS) for (combinatorial) optimization problems heavily relies on so-called instance features, i.e., numerical characteristics of the problem at hand ideally extracted with computationally low-demanding routines. For the traveling salesperson problem (TSP) a plethora of features have been suggested. Most of these features are, if at all, only normalized imprecisely raising the issue of feature values being strongly affected by the instance size. Such artifacts may have detrimental effects on algorithm selection models. We propose a normalization for two feature groups which stood out in multiple AS studies on the TSP: (a) features based on a minimum spanning tree (MST) and (b) nearest neighbor relationships of the input instance. To this end we theoretically derive minimum and maximum values for properties of MSTs and k-nearest neighbor graphs (NNG) of Euclidean graphs. We analyze the differences in feature space between normalized versions of these features and their unnormalized counterparts. Our empirical investigations on various TSP benchmark sets point out that the feature scaling succeeds in eliminating the effect of the instance size. A proof-of-concept AS-study shows promising results: models trained with normalized features tend to outperform those trained with the respective vanilla features.}},
  author       = {{Heins, Jonathan and Bossek, Jakob and Pohl, Janina and Seiler, Moritz and Trautmann, Heike and Kerschke, Pascal}},
  issn         = {{0304-3975}},
  journal      = {{Theoretical Computer Science}},
  keywords     = {{Algorithm selection, Feature normalization, Traveling salesperson problem}},
  pages        = {{123–145}},
  title        = {{{A Study on the Effects of Normalized TSP Features for Automated Algorithm Selection}}},
  doi          = {{10.1016/j.tcs.2022.10.019}},
  volume       = {{940}},
  year         = {{2023}},
}

@article{48871,
  abstract     = {{Most runtime analyses of randomised search heuristics focus on the expected number of function evaluations to find a unique global optimum. We ask a fundamental question: if additional search points are declared optimal, or declared as desirable target points, do these additional optima speed up evolutionary algorithms? More formally, we analyse the expected hitting time of a target set OPT{$\cup$}S where S is a set of non-optimal search points and OPT is the set of optima and compare it to the expected hitting time of OPT. We show that the answer to our question depends on the number and placement of search points in S. For all black-box algorithms and all fitness functions with polynomial expected optimisation times we show that, if additional optima are placed randomly, even an exponential number of optima has a negligible effect on the expected optimisation time. Considering Hamming balls around all global optima gives an easier target for some algorithms and functions and can shift the phase transition with respect to offspring population sizes in the (1,{$\lambda$}) EA on OneMax. However, for the one-dimensional Ising model the time to reach Hamming balls of radius (1/2-{$ϵ$})n around optima does not reduce the asymptotic expected optimisation time in the worst case. Finally, on functions where search trajectories typically join in a single search point, turning one search point into an optimum drastically reduces the expected optimisation time.}},
  author       = {{Bossek, Jakob and Sudholt, Dirk}},
  issn         = {{0304-3975}},
  journal      = {{Theoretical Computer Science}},
  keywords     = {{Evolutionary algorithms, pseudo-Boolean functions, runtime analysis}},
  pages        = {{113757}},
  title        = {{{Do Additional Target Points Speed Up Evolutionary Algorithms?}}},
  doi          = {{10.1016/j.tcs.2023.113757}},
  year         = {{2023}},
}

@article{48859,
  abstract     = {{We contribute to the efficient approximation of the Pareto-set for the classical NP-hard multi-objective minimum spanning tree problem (moMST) adopting evolutionary computation. More precisely, by building upon preliminary work, we analyse the neighborhood structure of Pareto-optimal spanning trees and design several highly biased sub-graph-based mutation operators founded on the gained insights. In a nutshell, these operators replace (un)connected sub-trees of candidate solutions with locally optimal sub-trees. The latter (biased) step is realized by applying Kruskal’s single-objective MST algorithm to a weighted sum scalarization of a sub-graph.We prove runtime complexity results for the introduced operators and investigate the desirable Pareto-beneficial property. This property states that mutants cannot be dominated by their parent. Moreover, we perform an extensive experimental benchmark study to showcase the operator’s practical suitability. Our results confirm that the subgraph based operators beat baseline algorithms from the literature even with severely restricted computational budget in terms of function evaluations on four different classes of complete graphs with different shapes of the Pareto-front.}},
  author       = {{Bossek, Jakob and Grimme, Christian}},
  issn         = {{1063-6560}},
  journal      = {{Evolutionary Computation}},
  pages        = {{1–35}},
  title        = {{{On Single-Objective Sub-Graph-Based Mutation for Solving the Bi-Objective Minimum Spanning Tree Problem}}},
  doi          = {{10.1162/evco_a_00335}},
  year         = {{2023}},
}

@inproceedings{47522,
  abstract     = {{Artificial benchmark functions are commonly used in optimization research because of their ability to rapidly evaluate potential solutions, making them a preferred substitute for real-world problems. However, these benchmark functions have faced criticism for their limited resemblance to real-world problems. In response, recent research has focused on automatically generating new benchmark functions for areas where established test suites are inadequate. These approaches have limitations, such as the difficulty of generating new benchmark functions that exhibit exploratory landscape analysis (ELA) features beyond those of existing benchmarks.The objective of this work is to develop a method for generating benchmark functions for single-objective continuous optimization with user-specified structural properties. Specifically, we aim to demonstrate a proof of concept for a method that uses an ELA feature vector to specify these properties in advance. To achieve this, we begin by generating a random sample of decision space variables and objective values. We then adjust the objective values using CMA-ES until the corresponding features of our new problem match the predefined ELA features within a specified threshold. By iteratively transforming the landscape in this way, we ensure that the resulting function exhibits the desired properties. To create the final function, we use the resulting point cloud as training data for a simple neural network that produces a function exhibiting the target ELA features. We demonstrate the effectiveness of this approach by replicating the existing functions of the well-known BBOB suite and creating new functions with ELA feature values that are not present in BBOB.}},
  author       = {{Prager, Raphael Patrick and Dietrich, Konstantin and Schneider, Lennart and Schäpermeier, Lennart and Bischl, Bernd and Kerschke, Pascal and Trautmann, Heike and Mersmann, Olaf}},
  booktitle    = {{Proceedings of the 17th ACM/SIGEVO Conference on Foundations of Genetic Algorithms}},
  isbn         = {{9798400702020}},
  keywords     = {{Benchmarking, Instance Generator, Black-Box Continuous Optimization, Exploratory Landscape Analysis, Neural Networks}},
  pages        = {{129–139}},
  publisher    = {{Association for Computing Machinery}},
  title        = {{{Neural Networks as Black-Box Benchmark Functions Optimized for Exploratory Landscape Features}}},
  doi          = {{10.1145/3594805.3607136}},
  year         = {{2023}},
}

@inproceedings{46297,
  abstract     = {{Exploratory landscape analysis (ELA) in single-objective black-box optimization relies on a comprehensive and large set of numerical features characterizing problem instances. Those foster problem understanding and serve as basis for constructing automated algorithm selection models choosing the best suited algorithm for a problem at hand based on the aforementioned features computed prior to optimization. This work specifically points to the sensitivity of a substantial proportion of these features to absolute objective values, i.e., we observe a lack of shift and scale invariance. We show that this unfortunately induces bias within automated algorithm selection models, an overfitting to specific benchmark problem sets used for training and thereby hinders generalization capabilities to unseen problems. We tackle these issues by presenting an appropriate objective normalization to be used prior to ELA feature computation and empirically illustrate the respective effectiveness focusing on the BBOB benchmark set.}},
  author       = {{Prager, Raphael Patrick and Trautmann, Heike}},
  booktitle    = {{Applications of Evolutionary Computation}},
  editor       = {{Correia, João and Smith, Stephen and Qaddoura, Raneem}},
  isbn         = {{978-3-031-30229-9}},
  pages        = {{411–425}},
  publisher    = {{Springer Nature Switzerland}},
  title        = {{{Nullifying the Inherent Bias of Non-invariant Exploratory Landscape Analysis Features}}},
  year         = {{2023}},
}

@inproceedings{46298,
  abstract     = {{The design and choice of benchmark suites are ongoing topics of discussion in the multi-objective optimization community. Some suites provide a good understanding of their Pareto sets and fronts, such as the well-known DTLZ and ZDT problems. However, they lack diversity in their landscape properties and do not provide a mechanism for creating multiple distinct problem instances. Other suites, like bi-objective BBOB, possess diverse and challenging landscape properties, but their optima are not well understood and can only be approximated empirically without any guarantees.}},
  author       = {{Schäpermeier, Lennart and Kerschke, Pascal and Grimme, Christian and Trautmann, Heike}},
  booktitle    = {{Evolutionary Multi-Criterion Optimization}},
  editor       = {{Emmerich, Michael and Deutz, André and Wang, Hao and Kononova, Anna V. and Naujoks, Boris and Li, Ke and Miettinen, Kaisa and Yevseyeva, Iryna}},
  isbn         = {{978-3-031-27250-9}},
  pages        = {{291–304}},
  publisher    = {{Springer Nature Switzerland}},
  title        = {{{Peak-A-Boo! Generating Multi-objective Multiple Peaks Benchmark Problems with Precise Pareto Sets}}},
  year         = {{2023}},
}

@inproceedings{48886,
  abstract     = {{Generating new instances via evolutionary methods is commonly used to create new benchmarking data-sets, with a focus on attempting to cover an instance-space as completely as possible. Recent approaches have exploited Quality-Diversity methods to evolve sets of instances that are both diverse and discriminatory with respect to a portfolio of solvers, but these methods can be challenging when attempting to find diversity in a high-dimensional feature-space. We address this issue by training a model based on Principal Component Analysis on existing instances to create a low-dimension projection of the high-dimension feature-vectors, and then apply Novelty Search directly in the new low-dimension space. We conduct experiments to evolve diverse and discriminatory instances of Knapsack Problems, comparing the use of Novelty Search in the original feature-space to using Novelty Search in a low-dimensional projection, and repeat over a given set of dimensions. We find that the methods are complementary: if treated as an ensemble, they collectively provide increased coverage of the space. Specifically, searching for novelty in a low-dimension space contributes 56% of the filled regions of the space, while searching directly in the feature-space covers the remaining 44%.}},
  author       = {{Marrero, Alejandro and Segredo, Eduardo and Hart, Emma and Bossek, Jakob and Neumann, Aneta}},
  booktitle    = {{Proceedings of the Genetic} and Evolutionary Computation Conference},
  isbn         = {{9798400701191}},
  keywords     = {{evolutionary computation, instance generation, instance-space analysis, knapsack problem, novelty search}},
  pages        = {{312–320}},
  publisher    = {{Association for Computing Machinery}},
  title        = {{{Generating Diverse and Discriminatory Knapsack Instances by Searching for Novelty in Variable Dimensions of Feature-Space}}},
  doi          = {{10.1145/3583131.3590504}},
  year         = {{2023}},
}

@inproceedings{48898,
  abstract     = {{Automated Algorithm Configuration (AAC) usually takes a global perspective: it identifies a parameter configuration for an (optimization) algorithm that maximizes a performance metric over a set of instances. However, the optimal choice of parameters strongly depends on the instance at hand and should thus be calculated on a per-instance basis. We explore the potential of Per-Instance Algorithm Configuration (PIAC) by using Reinforcement Learning (RL). To this end, we propose a novel PIAC approach that is based on deep neural networks. We apply it to predict configurations for the Lin\textendash Kernighan heuristic (LKH) for the Traveling Salesperson Problem (TSP) individually for every single instance. To train our PIAC approach, we create a large set of 100000 TSP instances with 2000 nodes each \textemdash currently the largest benchmark set to the best of our knowledge. We compare our approach to the state-of-the-art AAC method Sequential Model-based Algorithm Configuration (SMAC). The results show that our PIAC approach outperforms this baseline on both the newly created instance set and established instance sets.}},
  author       = {{Seiler, Moritz Vinzent and Rook, Jeroen and Heins, Jonathan and Preuß, Oliver and Bossek, Jakob and Trautmann, Heike}},
  booktitle    = {{2023 IEEE Symposium Series on Computational Intelligence (SSCI)}},
  title        = {{{Using Reinforcement Learning for Per-Instance Algorithm Configuration on the TSP}}},
  year         = {{2023}},
  pages        = {{361-368}},
  doi          = {{10.1109/SSCI52147.2023.10372008}}
}


@inproceedings{48869,
  abstract     = {{Evolutionary algorithms have been shown to obtain good solutions for complex optimization problems in static and dynamic environments. It is important to understand the behaviour of evolutionary algorithms for complex optimization problems that also involve dynamic and/or stochastic components in a systematic way in order to further increase their applicability to real-world problems. We investigate the node weighted traveling salesperson problem (W-TSP), which provides an abstraction of a wide range of weighted TSP problems, in dynamic settings. In the dynamic setting of the problem, items that have to be collected as part of a TSP tour change over time. We first present a dynamic setup for the dynamic W-TSP parameterized by different types of changes that are applied to the set of items to be collected when traversing the tour. Our first experimental investigations study the impact of such changes on resulting optimized tours in order to provide structural insights of optimization solutions. Afterwards, we investigate simple mutation-based evolutionary algorithms and study the impact of the mutation operators and the use of populations with dealing with the dynamic changes to the node weights of the problem.}},
  author       = {{Bossek, Jakob and Neumann, Aneta and Neumann, Frank}},
  booktitle    = {{Proceedings of the Genetic and Evolutionary Computation Conference}},
  isbn         = {{9798400701191}},
  keywords     = {{dynamic optimization, evolutionary algorithms, re-optimization, weighted traveling salesperson problem}},
  pages        = {{248–256}},
  publisher    = {{Association for Computing Machinery}},
  title        = {{{On the Impact of Basic Mutation Operators and Populations within Evolutionary Algorithms for the Dynamic Weighted Traveling Salesperson Problem}}},
  doi          = {{10.1145/3583131.3590384}},
  year         = {{2023}},
}

@inproceedings{48872,
  abstract     = {{Quality diversity (QD) is a branch of evolutionary computation that gained increasing interest in recent years. The Map-Elites QD approach defines a feature space, i.e., a partition of the search space, and stores the best solution for each cell of this space. We study a simple QD algorithm in the context of pseudo-Boolean optimisation on the "number of ones" feature space, where the ith cell stores the best solution amongst those with a number of ones in [(i - 1)k, ik - 1]. Here k is a granularity parameter 1 {$\leq$} k {$\leq$} n+1. We give a tight bound on the expected time until all cells are covered for arbitrary fitness functions and for all k and analyse the expected optimisation time of QD on OneMax and other problems whose structure aligns favourably with the feature space. On combinatorial problems we show that QD finds a (1 - 1/e)-approximation when maximising any monotone sub-modular function with a single uniform cardinality constraint efficiently. Defining the feature space as the number of connected components of a connected graph, we show that QD finds a minimum spanning tree in expected polynomial time.}},
  author       = {{Bossek, Jakob and Sudholt, Dirk}},
  booktitle    = {{Proceedings of the Genetic and Evolutionary Computation Conference}},
  isbn         = {{9798400701191}},
  keywords     = {{quality diversity, runtime analysis}},
  pages        = {{1546–1554}},
  publisher    = {{Association for Computing Machinery}},
  title        = {{{Runtime Analysis of Quality Diversity Algorithms}}},
  doi          = {{10.1145/3583131.3590383}},
  year         = {{2023}},
}

